# E-Commerce Analytics Platform - Deployment & Configuration Guide

## Overview

This guide provides comprehensive instructions for deploying the E-Commerce Analytics Platform (ECAP) across different environments, from local development to production-ready Kubernetes clusters. The platform supports multiple deployment strategies with comprehensive configuration management and monitoring.

## Table of Contents

1. [Quick Start Guide](#quick-start-guide)
2. [Local Development Environment](#local-development-environment)
3. [Docker Deployment](#docker-deployment)
4. [Kubernetes Deployment](#kubernetes-deployment)
5. [Production Deployment](#production-deployment)
6. [Configuration Management](#configuration-management)
7. [Environment Variables](#environment-variables)
8. [Security Configuration](#security-configuration)
9. [Monitoring & Observability](#monitoring--observability)
10. [Backup & Disaster Recovery](#backup--disaster-recovery)
11. [Performance Tuning](#performance-tuning)
12. [Troubleshooting](#troubleshooting)

## Quick Start Guide

### Prerequisites

- **Docker** 20.10+ and **Docker Compose** 2.0+
- **Python** 3.9+ with **Poetry** 1.4+
- **Git** for version control
- **Make** for build automation
- **curl** and **jq** for testing

### 5-Minute Setup

```bash
# 1. Clone the repository
git clone https://github.com/your-org/e-commerce-analytics-platform.git
cd e-commerce-analytics-platform

# 2. Install dependencies
make install-dev

# 3. Start all services
make docker-up

# 4. Initialize the system
make setup-dev

# 5. Verify deployment
make health-check
```

**Access URLs:**
- **API**: http://localhost:8000/docs
- **Dashboard**: http://localhost:8501
- **Monitoring**: http://localhost:3000 (Grafana)

## Local Development Environment

### Manual Setup

#### 1. Environment Preparation

```bash
# Create and activate Python virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install Poetry (if not already installed)
curl -sSL https://install.python-poetry.org | python3 -

# Install project dependencies
poetry install

# Install pre-commit hooks
poetry run pre-commit install
```

#### 2. Service Dependencies

**Start Infrastructure Services:**
```bash
# Start only infrastructure components
docker-compose -f docker-compose.yml up -d zookeeper kafka postgres redis minio

# Wait for services to be ready
./scripts/wait-for-services.sh
```

**Create Kafka Topics:**
```bash
# Create required Kafka topics
./scripts/kafka-topics.sh create

# Verify topic creation
./scripts/kafka-topics.sh list
```

#### 3. Database Setup

```bash
# Initialize database schema
poetry run alembic upgrade head

# (Optional) Seed with sample data
poetry run python -m scripts.seed_data
```

#### 4. Configuration

```bash
# Copy example configuration
cp config/local.yaml.example config/local.yaml

# Edit configuration as needed
vim config/local.yaml
```

#### 5. Run Services

```bash
# Terminal 1: Start API server
make run-api

# Terminal 2: Start dashboard
make run-dashboard

# Terminal 3: Start streaming consumer
poetry run python -m src.streaming.consumer_cli

# Terminal 4: Start data producers (optional)
poetry run python -m src.data_ingestion.producers.transaction_producer
```

### Development Tools

#### Code Quality

```bash
# Run linting
make lint

# Auto-format code
make format

# Type checking
make type-check

# Run all quality checks
make quality-check
```

#### Testing

```bash
# Run all tests
make test

# Run specific test categories
make test-unit
make test-integration
make test-performance

# Generate coverage report
make test-coverage
```

#### Debugging

```bash
# Run with debug logging
ECAP_LOG_LEVEL=debug make run-api

# Enable SQL query logging
ECAP_DATABASE_ECHO=true make run-api

# Profile API performance
ECAP_ENABLE_PROFILING=true make run-api
```

## Docker Deployment

### Single-Machine Docker Deployment

#### 1. Using Docker Compose

**Start Full Stack:**
```bash
# Start all services
docker-compose up -d

# View logs
docker-compose logs -f

# Check service health
docker-compose ps
```

**Environment-Specific Deployments:**
```bash
# Development environment
docker-compose -f docker-compose.yml -f docker-compose.dev.yml up -d

# Staging environment
docker-compose -f docker-compose.yml -f docker-compose.staging.yml up -d

# Production environment
docker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d
```

#### 2. Custom Build

```bash
# Build custom images
make docker-build

# Build with specific tags
docker build -t ecap-api:latest -f docker/api/Dockerfile .
docker build -t ecap-dashboard:latest -f docker/dashboard/Dockerfile .
docker build -t ecap-streaming:latest -f docker/streaming/Dockerfile .
```

#### 3. Docker Service Configuration

**docker-compose.yml Services:**

```yaml
services:
  # Infrastructure
  zookeeper:      # Kafka coordination
  kafka:          # Message streaming
  postgres:       # Operational database
  redis:          # Caching layer
  minio:          # Object storage

  # Core Services
  api:            # FastAPI REST API
  dashboard:      # Streamlit dashboard
  streaming:      # Spark streaming consumer

  # Data Generation
  transaction-producer:    # Transaction data
  user-behavior-producer: # User behavior data

  # Monitoring
  prometheus:     # Metrics collection
  grafana:        # Metrics visualization
  jaeger:         # Distributed tracing
```

#### 4. Docker Networking

```bash
# View network configuration
docker network ls
docker network inspect ecap-network

# Service discovery testing
docker-compose exec api ping kafka
docker-compose exec streaming curl postgres:5432
```

### Multi-Host Docker Swarm

#### 1. Swarm Initialization

```bash
# Initialize swarm on manager node
docker swarm init --advertise-addr <MANAGER-IP>

# Add worker nodes
docker swarm join --token <TOKEN> <MANAGER-IP>:2377

# Verify cluster
docker node ls
```

#### 2. Deploy Stack

```bash
# Deploy ECAP stack
docker stack deploy -c docker-compose.swarm.yml ecap

# Monitor deployment
docker stack services ecap
docker stack ps ecap
```

#### 3. Scaling Services

```bash
# Scale API service
docker service scale ecap_api=3

# Scale streaming consumers
docker service scale ecap_streaming=2

# Auto-scaling (with Traefik)
docker service update --replicas 5 ecap_api
```

## Kubernetes Deployment

### Prerequisites

- **Kubernetes** 1.25+ cluster
- **Helm** 3.8+
- **kubectl** configured for your cluster
- **Persistent storage** provider

### 1. Namespace Setup

```bash
# Create namespace
kubectl create namespace ecap

# Set default namespace
kubectl config set-context --current --namespace=ecap

# Create service account
kubectl apply -f k8s/rbac/
```

### 2. Helm Deployment

#### Install Dependencies

```bash
# Add Helm repositories
helm repo add bitnami https://charts.bitnami.com/bitnami
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo add grafana https://grafana.github.io/helm-charts
helm repo update

# Install infrastructure dependencies
helm install kafka bitnami/kafka -f helm/kafka-values.yaml
helm install postgresql bitnami/postgresql -f helm/postgres-values.yaml
helm install redis bitnami/redis -f helm/redis-values.yaml
```

#### Deploy ECAP

```bash
# Install ECAP application
helm install ecap ./helm/ecap -f helm/values.yaml

# Upgrade deployment
helm upgrade ecap ./helm/ecap -f helm/values.yaml

# Rollback if needed
helm rollback ecap 1
```

#### Custom Values

```yaml
# helm/values.yaml
global:
  environment: production
  registry: your-registry.com/ecap

api:
  replicas: 3
  resources:
    requests:
      cpu: 500m
      memory: 1Gi
    limits:
      cpu: 2
      memory: 4Gi

streaming:
  replicas: 2
  resources:
    requests:
      cpu: 1
      memory: 2Gi
    limits:
      cpu: 4
      memory: 8Gi
```

### 3. Manual K8s Deployment

#### Core Services

```bash
# Deploy in order
kubectl apply -f k8s/configmaps/
kubectl apply -f k8s/secrets/
kubectl apply -f k8s/storage/
kubectl apply -f k8s/services/
kubectl apply -f k8s/deployments/
kubectl apply -f k8s/ingress/
```

#### Ingress Configuration

```yaml
# k8s/ingress/ecap-ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ecap-ingress
  annotations:
    kubernetes.io/ingress.class: nginx
    cert-manager.io/cluster-issuer: letsencrypt-prod
spec:
  tls:
  - hosts:
    - api.ecap.example.com
    - dashboard.ecap.example.com
    secretName: ecap-tls
  rules:
  - host: api.ecap.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: ecap-api
            port:
              number: 8000
```

### 4. Monitoring & Observability

```bash
# Install monitoring stack
helm install prometheus prometheus-community/kube-prometheus-stack
helm install jaeger jaegertracing/jaeger-operator

# Port forward for access
kubectl port-forward svc/prometheus-grafana 3000:80
kubectl port-forward svc/jaeger-query 16686:16686
```

### 5. Auto-scaling

```yaml
# k8s/hpa/api-hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: ecap-api-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: ecap-api
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

## Production Deployment

### Architecture Overview

**Production Stack:**
- **Load Balancer**: NGINX/AWS ALB/GCP Load Balancer
- **Container Orchestration**: Kubernetes (EKS/GKE/AKS)
- **Service Mesh**: Istio (optional)
- **Databases**: Amazon RDS PostgreSQL, ElastiCache Redis
- **Streaming**: Amazon MSK (Managed Kafka)
- **Storage**: Amazon S3/Google Cloud Storage
- **Monitoring**: Prometheus + Grafana + Jaeger
- **Logging**: ELK Stack
- **CI/CD**: GitHub Actions + ArgoCD

### 1. Cloud Provider Setup

#### AWS Deployment

```bash
# Create EKS cluster
eksctl create cluster --config-file=deploy/aws/eks-cluster.yaml

# Install AWS Load Balancer Controller
kubectl apply -k "github.com/aws/eks-charts/stable/aws-load-balancer-controller//crds?ref=master"
helm install aws-load-balancer-controller eks/aws-load-balancer-controller

# Setup external services
aws rds create-db-instance --db-name ecap --engine postgres
aws kafka create-cluster --cluster-name ecap-kafka
aws s3 mb s3://ecap-data-lake
```

#### GCP Deployment

```bash
# Create GKE cluster
gcloud container clusters create ecap-cluster \
  --zone us-central1-a \
  --num-nodes 3 \
  --machine-type n1-standard-4

# Setup managed services
gcloud sql instances create ecap-postgres --tier=db-n1-standard-2
gcloud pubsub topics create transactions user-events
gsutil mb gs://ecap-data-lake
```

### 2. Production Configuration

#### High Availability Setup

```yaml
# Production values for high availability
api:
  replicas: 5
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 50%
      maxUnavailable: 25%

  affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchExpressions:
            - key: app
              operator: In
              values:
              - ecap-api
          topologyKey: kubernetes.io/hostname

  resources:
    requests:
      cpu: 1
      memory: 2Gi
    limits:
      cpu: 4
      memory: 8Gi
```

#### Database Configuration

```yaml
# Production database settings
database:
  # Connection pooling
  pool_size: 20
  max_overflow: 50
  pool_timeout: 30
  pool_recycle: 3600

  # Performance tuning
  statement_timeout: 30000
  idle_in_transaction_session_timeout: 300000

  # High availability
  host: postgres-primary.internal
  read_replica_hosts:
    - postgres-replica-1.internal
    - postgres-replica-2.internal
```

### 3. SSL/TLS Configuration

```bash
# Install cert-manager
kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.12.0/cert-manager.yaml

# Create cluster issuer
kubectl apply -f - <<EOF
apiVersion: cert-manager.io/v1
kind: ClusterIssuer
metadata:
  name: letsencrypt-prod
spec:
  acme:
    server: https://acme-v02.api.letsencrypt.org/directory
    email: admin@example.com
    privateKeySecretRef:
      name: letsencrypt-prod
    solvers:
    - http01:
        ingress:
          class: nginx
EOF
```

### 4. Security Hardening

#### Network Policies

```yaml
# Restrict network access
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: ecap-network-policy
spec:
  podSelector:
    matchLabels:
      app: ecap-api
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: nginx-ingress
    ports:
    - protocol: TCP
      port: 8000
  egress:
  - to:
    - podSelector:
        matchLabels:
          app: postgres
    ports:
    - protocol: TCP
      port: 5432
```

#### Pod Security Standards

```yaml
# Pod security context
securityContext:
  runAsNonRoot: true
  runAsUser: 1000
  runAsGroup: 1000
  fsGroup: 1000
  seccompProfile:
    type: RuntimeDefault

containerSecurityContext:
  allowPrivilegeEscalation: false
  readOnlyRootFilesystem: true
  capabilities:
    drop:
    - ALL
```

## Configuration Management

### Configuration Hierarchy

The platform uses a hierarchical configuration system:

1. **Default values** (`config/default.yaml`)
2. **Environment-specific** (`config/{env}.yaml`)
3. **Local overrides** (`config/local.yaml`)
4. **Environment variables** (highest priority)

### Configuration Files

#### Base Configuration (`config/default.yaml`)

```yaml
app:
  name: "E-Commerce Analytics Platform"
  version: "1.0.0"
  debug: false

database:
  pool_size: 10
  max_overflow: 20
  pool_timeout: 30

kafka:
  bootstrap_servers: "localhost:9092"
  topics:
    transactions: "transactions"
    user_events: "user-events"

  consumer:
    group_id: "ecap-consumer-group"
    auto_offset_reset: "earliest"
    batch_size: 1000

redis:
  host: "localhost"
  port: 6379
  db: 0
  max_connections: 100

spark:
  app_name: "ECAP Streaming"
  master: "local[*]"
  executor_memory: "2g"
  driver_memory: "1g"
```

#### Production Configuration (`config/production.yaml`)

```yaml
app:
  debug: false

database:
  pool_size: 50
  max_overflow: 100
  statement_timeout: 30000

kafka:
  bootstrap_servers: "kafka-1:9092,kafka-2:9092,kafka-3:9092"
  consumer:
    batch_size: 5000
    max_poll_records: 2000

redis:
  host: "redis-cluster.internal"
  port: 6379
  max_connections: 200

spark:
  master: "k8s://https://kubernetes.default.svc:443"
  executor_instances: 10
  executor_memory: "4g"
  driver_memory: "2g"
```

### Secrets Management

#### HashiCorp Vault Integration

```python
# Using Vault for secrets
from src.config.vault_client import VaultClient

vault_client = VaultClient()
db_password = vault_client.get_secret('database/postgres/password')
api_keys = vault_client.get_secret('api/keys')
```

#### Kubernetes Secrets

```bash
# Create secrets
kubectl create secret generic ecap-secrets \
  --from-literal=database-password='super-secret-password' \
  --from-literal=jwt-secret='jwt-signing-key' \
  --from-literal=api-key='external-api-key'

# Mount secrets in pods
volumes:
- name: secrets
  secret:
    secretName: ecap-secrets
volumeMounts:
- name: secrets
  mountPath: "/etc/secrets"
  readOnly: true
```

## Environment Variables

### Core Environment Variables

```bash
# Application
ECAP_ENVIRONMENT=production
ECAP_LOG_LEVEL=info
ECAP_DEBUG=false

# Database
ECAP_DATABASE_URL=postgresql://user:pass@host:5432/ecap
ECAP_DATABASE_POOL_SIZE=20
ECAP_DATABASE_ECHO=false

# Kafka
ECAP_KAFKA_BOOTSTRAP_SERVERS=kafka1:9092,kafka2:9092
ECAP_KAFKA_CONSUMER_GROUP_ID=ecap-production
ECAP_KAFKA_AUTO_OFFSET_RESET=earliest

# Redis
ECAP_REDIS_URL=redis://redis-cluster:6379/0
ECAP_REDIS_MAX_CONNECTIONS=100

# Security
ECAP_SECRET_KEY=your-secret-key-here
ECAP_JWT_ALGORITHM=HS256
ECAP_JWT_EXPIRE_MINUTES=60

# API
ECAP_API_HOST=0.0.0.0
ECAP_API_PORT=8000
ECAP_API_WORKERS=4
ECAP_CORS_ORIGINS="https://dashboard.example.com,https://admin.example.com"

# Dashboard
ECAP_DASHBOARD_HOST=0.0.0.0
ECAP_DASHBOARD_PORT=8501

# Monitoring
ECAP_JAEGER_ENDPOINT=http://jaeger:14268/api/traces
ECAP_PROMETHEUS_GATEWAY=http://prometheus:9091

# Storage
ECAP_S3_BUCKET=ecap-data-lake
ECAP_S3_ACCESS_KEY=your-access-key
ECAP_S3_SECRET_KEY=your-secret-key
ECAP_S3_ENDPOINT=https://s3.amazonaws.com

# Spark
ECAP_SPARK_MASTER=k8s://https://kubernetes.default.svc:443
ECAP_SPARK_EXECUTOR_INSTANCES=5
ECAP_SPARK_EXECUTOR_MEMORY=4g
ECAP_SPARK_DRIVER_MEMORY=2g
```

### Environment-Specific Variables

#### Development
```bash
ECAP_ENVIRONMENT=development
ECAP_DEBUG=true
ECAP_LOG_LEVEL=debug
ECAP_DATABASE_ECHO=true
ECAP_API_RELOAD=true
```

#### Staging
```bash
ECAP_ENVIRONMENT=staging
ECAP_DEBUG=false
ECAP_LOG_LEVEL=info
ECAP_DATABASE_POOL_SIZE=10
ECAP_API_WORKERS=2
```

#### Production
```bash
ECAP_ENVIRONMENT=production
ECAP_DEBUG=false
ECAP_LOG_LEVEL=warning
ECAP_DATABASE_POOL_SIZE=50
ECAP_API_WORKERS=8
```

## Security Configuration

### Authentication & Authorization

#### JWT Configuration

```yaml
# JWT settings
jwt:
  secret_key: ${ECAP_JWT_SECRET_KEY}
  algorithm: HS256
  expire_minutes: 60
  refresh_expire_days: 30

  # Token validation
  verify_signature: true
  verify_expiration: true
  require_iat: true
  require_exp: true
```

#### API Key Management

```yaml
# API key configuration
api_keys:
  default_permissions:
    - read:analytics
    - read:customers

  rate_limits:
    default: 1000  # requests per hour
    premium: 5000  # requests per hour

  expiration:
    default: 365  # days
    service: null  # never expires
```

### Network Security

#### Firewall Rules

```bash
# AWS Security Groups
aws ec2 create-security-group --group-name ecap-api --description "ECAP API"
aws ec2 authorize-security-group-ingress --group-name ecap-api --protocol tcp --port 8000 --source-group ecap-lb

# GCP Firewall Rules
gcloud compute firewall-rules create ecap-api-access \
  --allow tcp:8000 \
  --source-tags ecap-lb \
  --target-tags ecap-api
```

#### TLS Configuration

```yaml
# TLS settings
tls:
  min_version: "1.2"
  ciphers:
    - "ECDHE-ECDSA-AES256-GCM-SHA384"
    - "ECDHE-RSA-AES256-GCM-SHA384"
    - "ECDHE-ECDSA-CHACHA20-POLY1305"
    - "ECDHE-RSA-CHACHA20-POLY1305"

  # Certificate settings
  cert_file: "/etc/ssl/certs/ecap.crt"
  key_file: "/etc/ssl/private/ecap.key"
  ca_file: "/etc/ssl/certs/ca.crt"
```

### Data Encryption

#### Encryption at Rest

```yaml
# Database encryption
database:
  ssl_mode: require
  ssl_cert: "/etc/ssl/certs/client.crt"
  ssl_key: "/etc/ssl/private/client.key"
  ssl_ca: "/etc/ssl/certs/ca.crt"

# S3 encryption
s3:
  server_side_encryption: "AES256"
  kms_key_id: "arn:aws:kms:region:account:key/key-id"
```

#### Encryption in Transit

```yaml
# Kafka SSL
kafka:
  security_protocol: "SSL"
  ssl_ca_location: "/etc/ssl/certs/ca.pem"
  ssl_certificate_location: "/etc/ssl/certs/client.pem"
  ssl_key_location: "/etc/ssl/private/client.key"

# Redis TLS
redis:
  ssl: true
  ssl_ca_certs: "/etc/ssl/certs/ca.pem"
  ssl_cert_reqs: required
```

## Monitoring & Observability

### Metrics Collection

#### Prometheus Configuration

```yaml
# prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
- job_name: 'ecap-api'
  static_configs:
  - targets: ['api:8000']
  metrics_path: '/metrics'
  scrape_interval: 5s

- job_name: 'ecap-streaming'
  static_configs:
  - targets: ['streaming:8080']
  metrics_path: '/metrics'

- job_name: 'kafka'
  static_configs:
  - targets: ['kafka:9308']

- job_name: 'postgres'
  static_configs:
  - targets: ['postgres-exporter:9187']
```

#### Custom Metrics

```python
# Application metrics
from prometheus_client import Counter, Histogram, Gauge

# API metrics
request_count = Counter('ecap_api_requests_total', 'Total API requests', ['method', 'endpoint', 'status'])
request_duration = Histogram('ecap_api_request_duration_seconds', 'API request duration')
active_connections = Gauge('ecap_api_active_connections', 'Active API connections')

# Business metrics
transaction_count = Counter('ecap_transactions_total', 'Total transactions processed')
fraud_alerts = Counter('ecap_fraud_alerts_total', 'Total fraud alerts', ['severity'])
customer_segments = Gauge('ecap_customer_segments', 'Customer segment counts', ['segment'])
```

### Logging

#### Structured Logging Configuration

```yaml
# Logging configuration
logging:
  version: 1
  disable_existing_loggers: false

  formatters:
    structured:
      format: '{"timestamp": "%(asctime)s", "level": "%(levelname)s", "logger": "%(name)s", "message": "%(message)s", "correlation_id": "%(correlation_id)s"}'
      datefmt: '%Y-%m-%dT%H:%M:%S.%fZ'

  handlers:
    console:
      class: logging.StreamHandler
      formatter: structured
      stream: ext://sys.stdout

    file:
      class: logging.handlers.RotatingFileHandler
      formatter: structured
      filename: /var/log/ecap/app.log
      maxBytes: 104857600  # 100MB
      backupCount: 10

  loggers:
    src:
      level: INFO
      handlers: [console, file]
      propagate: false

    uvicorn:
      level: INFO
      handlers: [console]
      propagate: false
```

#### ELK Stack Integration

```yaml
# Logstash configuration
input {
  beats {
    port => 5044
  }
}

filter {
  if [fields][service] == "ecap" {
    json {
      source => "message"
    }

    date {
      match => [ "timestamp", "ISO8601" ]
    }

    mutate {
      add_tag => ["ecap"]
    }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "ecap-logs-%{+YYYY.MM.dd}"
  }
}
```

### Distributed Tracing

#### Jaeger Configuration

```yaml
# Jaeger configuration
tracing:
  service_name: "ecap"
  jaeger:
    agent_host: "jaeger-agent"
    agent_port: 6831
    collector_endpoint: "http://jaeger-collector:14268/api/traces"

  # Sampling configuration
  sampling:
    type: "probabilistic"
    param: 0.1  # Sample 10% of traces

  # Tags
  tags:
    environment: "${ECAP_ENVIRONMENT}"
    version: "${ECAP_VERSION}"
```

### Alerting

#### Alert Rules

```yaml
# Alert rules
groups:
- name: ecap.rules
  rules:
  # High error rate
  - alert: HighErrorRate
    expr: rate(ecap_api_requests_total{status=~"5.."}[5m]) > 0.1
    for: 2m
    labels:
      severity: critical
    annotations:
      summary: "High error rate detected"
      description: "Error rate is {{ $value }} requests per second"

  # High response time
  - alert: HighResponseTime
    expr: histogram_quantile(0.95, rate(ecap_api_request_duration_seconds_bucket[5m])) > 2
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High response time detected"
      description: "95th percentile response time is {{ $value }} seconds"

  # Database connection issues
  - alert: DatabaseConnectionFailure
    expr: ecap_database_connections_failed_total > 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "Database connection failures"
      description: "{{ $value }} database connection failures in the last minute"
```

## Backup & Disaster Recovery

### Backup Strategy

#### Database Backups

```bash
# Automated PostgreSQL backups
#!/bin/bash
# backup-postgres.sh

BACKUP_DIR="/backups/postgres"
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_NAME="ecap_backup_${DATE}.sql"

# Create backup
pg_dump \
  --host=${POSTGRES_HOST} \
  --port=${POSTGRES_PORT} \
  --username=${POSTGRES_USER} \
  --no-password \
  --format=custom \
  --blobs \
  --verbose \
  ecap > "${BACKUP_DIR}/${BACKUP_NAME}"

# Compress backup
gzip "${BACKUP_DIR}/${BACKUP_NAME}"

# Upload to S3
aws s3 cp "${BACKUP_DIR}/${BACKUP_NAME}.gz" \
  "s3://ecap-backups/postgres/${BACKUP_NAME}.gz"

# Cleanup old backups (keep last 30 days)
find "${BACKUP_DIR}" -name "*.gz" -mtime +30 -delete
```

#### Data Lake Backups

```bash
# Backup Delta Lake tables
#!/bin/bash
# backup-delta-lake.sh

SOURCE_BUCKET="ecap-data-lake"
BACKUP_BUCKET="ecap-data-lake-backup"
DATE=$(date +%Y%m%d)

# Sync with versioning
aws s3 sync \
  "s3://${SOURCE_BUCKET}/" \
  "s3://${BACKUP_BUCKET}/${DATE}/" \
  --delete \
  --storage-class GLACIER

# Create manifest
aws s3 ls "s3://${BACKUP_BUCKET}/${DATE}/" --recursive > \
  "/tmp/backup_manifest_${DATE}.txt"

aws s3 cp "/tmp/backup_manifest_${DATE}.txt" \
  "s3://${BACKUP_BUCKET}/manifests/"
```

### Disaster Recovery

#### RTO/RPO Targets

| Component | RTO | RPO | Recovery Strategy |
|-----------|-----|-----|-------------------|
| API Service | 5 minutes | 0 | Blue-green deployment |
| Database | 15 minutes | 5 minutes | Point-in-time recovery |
| Streaming | 10 minutes | 1 minute | Kafka replay |
| Data Lake | 30 minutes | 15 minutes | S3 cross-region replication |
| Dashboard | 5 minutes | 0 | Stateless service |

#### Disaster Recovery Procedures

```bash
# 1. Database Recovery
# Point-in-time recovery
aws rds restore-db-instance-to-point-in-time \
  --source-db-instance-identifier ecap-prod \
  --target-db-instance-identifier ecap-recovery \
  --restore-time 2024-01-15T10:00:00Z

# 2. Kafka Recovery
# Reset consumer group to specific offset
kafka-consumer-groups.sh \
  --bootstrap-server kafka:9092 \
  --group ecap-consumer-group \
  --reset-offsets \
  --to-datetime 2024-01-15T10:00:00.000 \
  --all-topics \
  --execute

# 3. Application Recovery
# Deploy from backup configuration
kubectl apply -f disaster-recovery/ecap-recovery.yaml

# Scale up services
kubectl scale deployment ecap-api --replicas=5
kubectl scale deployment ecap-streaming --replicas=3
```

## Performance Tuning

### Database Optimization

#### PostgreSQL Configuration

```sql
-- postgresql.conf optimizations
shared_buffers = '4GB'
effective_cache_size = '12GB'
maintenance_work_mem = '1GB'
checkpoint_completion_target = 0.9
wal_buffers = '16MB'
default_statistics_target = 100
random_page_cost = 1.1
effective_io_concurrency = 200

-- Connection pooling
max_connections = 200
shared_preload_libraries = 'pg_stat_statements'

-- Indexes for common queries
CREATE INDEX CONCURRENTLY idx_transactions_customer_id ON transactions(customer_id);
CREATE INDEX CONCURRENTLY idx_transactions_timestamp ON transactions(created_at);
CREATE INDEX CONCURRENTLY idx_customers_segment ON customers(rfm_segment);
```

#### Query Optimization

```sql
-- Optimized customer analytics query
EXPLAIN (ANALYZE, BUFFERS, FORMAT JSON)
SELECT
    c.segment,
    COUNT(*) as customer_count,
    AVG(c.total_spent) as avg_spent
FROM customers c
WHERE c.last_purchase_date >= CURRENT_DATE - INTERVAL '90 days'
    AND c.is_active = true
GROUP BY c.segment
HAVING COUNT(*) > 100
ORDER BY avg_spent DESC;

-- Add missing indexes based on query plans
CREATE INDEX CONCURRENTLY idx_customers_last_purchase_active
ON customers(last_purchase_date, is_active)
WHERE is_active = true;
```

### Kafka Optimization

#### Producer Configuration

```yaml
kafka:
  producer:
    # Throughput optimization
    batch_size: 65536
    linger_ms: 20
    buffer_memory: 134217728
    compression_type: snappy

    # Reliability
    acks: 1
    retries: 2147483647
    max_in_flight_requests_per_connection: 5
    enable_idempotence: true

    # Performance tuning
    max_request_size: 1048576
    send_buffer_bytes: 131072
    receive_buffer_bytes: 65536
```

#### Consumer Configuration

```yaml
kafka:
  consumer:
    # Processing optimization
    fetch_min_bytes: 50000
    fetch_max_wait_ms: 500
    max_poll_records: 2000
    max_poll_interval_ms: 300000

    # Memory management
    receive_buffer_bytes: 65536
    send_buffer_bytes: 131072

    # Offset management
    enable_auto_commit: false
    auto_offset_reset: earliest
```

### Spark Optimization

#### Cluster Configuration

```yaml
spark:
  # Driver settings
  driver:
    memory: "4g"
    cores: 2
    max_result_size: "2g"

  # Executor settings
  executor:
    instances: 10
    memory: "8g"
    cores: 4
    memory_fraction: 0.8

  # Performance tuning
  sql:
    adaptive:
      enabled: true
      coalescePartitions:
        enabled: true
        minPartitionNum: 1
      skewJoin:
        enabled: true

  # Serialization
  serializer: "org.apache.spark.serializer.KryoSerializer"

  # Network
  network:
    timeout: "300s"

  # Shuffle optimization
  sql:
    shuffle:
      partitions: 400
  shuffle:
    compress: true
    spill:
      compress: true
```

### API Performance

#### FastAPI Optimization

```python
# Production ASGI server configuration
import uvicorn

uvicorn.run(
    "src.api.main:app",
    host="0.0.0.0",
    port=8000,
    workers=8,  # CPU cores * 2
    worker_class="uvicorn.workers.UvicornWorker",
    loop="uvloop",  # Fast event loop
    http="httptools",  # Fast HTTP parser
    access_log=False,  # Disable for performance
    log_level="warning",
    keepalive_timeout=5,
    max_concurrent_connections=1000,
)
```

#### Caching Strategy

```python
# Multi-level caching
from src.api.services.cache import CacheService

# L1: Application-level cache (in-memory)
app_cache = TTLCache(maxsize=1000, ttl=300)

# L2: Redis distributed cache
redis_cache = CacheService(ttl=3600)

# L3: Database query result cache
@lru_cache(maxsize=100)
def get_customer_segments():
    return db.execute("SELECT * FROM customer_segments").fetchall()
```

## Troubleshooting

### Common Issues

#### Service Connectivity

```bash
# Test service connectivity
curl -f http://api:8000/health || echo "API service down"
curl -f http://dashboard:8501/health || echo "Dashboard service down"

# Check DNS resolution
nslookup postgres
nslookup kafka

# Test database connection
psql -h postgres -U ecap_user -d ecap -c "SELECT 1;"

# Test Kafka connectivity
kafka-console-producer.sh --bootstrap-server kafka:9092 --topic test
kafka-console-consumer.sh --bootstrap-server kafka:9092 --topic test --from-beginning
```

#### Memory Issues

```bash
# Check memory usage
docker stats
kubectl top pods

# Spark memory issues
# Check driver logs
kubectl logs spark-driver-pod

# Check executor logs
kubectl logs spark-executor-pod

# Java heap dump analysis
jmap -dump:format=b,file=heap.hprof <PID>
```

#### Performance Issues

```bash
# Profile API endpoints
curl -w "@curl-format.txt" -o /dev/null -s "http://api:8000/api/v1/analytics/revenue"

# Database query performance
psql -c "EXPLAIN (ANALYZE, BUFFERS) SELECT * FROM transactions WHERE customer_id = 123;"

# Kafka lag monitoring
kafka-consumer-groups.sh --bootstrap-server kafka:9092 --describe --group ecap-consumer-group
```

### Debugging Tools

#### Container Debugging

```bash
# Enter running container
docker exec -it ecap-api /bin/bash
kubectl exec -it pod/ecap-api-xxx -- /bin/bash

# View container logs
docker logs ecap-api --tail 100 -f
kubectl logs deployment/ecap-api -f

# Resource usage
docker stats ecap-api
kubectl top pod ecap-api-xxx
```

#### Application Debugging

```bash
# Enable debug logging
export ECAP_LOG_LEVEL=debug

# Enable SQL query logging
export ECAP_DATABASE_ECHO=true

# Enable profiling
export ECAP_ENABLE_PROFILING=true

# Generate thread dump
kill -3 <java-pid>

# Check application health
curl http://localhost:8000/health
curl http://localhost:8000/metrics
```

### Health Checks

#### Comprehensive Health Check Script

```bash
#!/bin/bash
# health-check.sh

echo "=== ECAP Health Check ==="

# API Health
echo -n "API Service: "
if curl -sf http://localhost:8000/health > /dev/null; then
    echo "✓ Healthy"
else
    echo "✗ Unhealthy"
fi

# Database Health
echo -n "Database: "
if pg_isready -h localhost -p 5432 > /dev/null; then
    echo "✓ Healthy"
else
    echo "✗ Unhealthy"
fi

# Kafka Health
echo -n "Kafka: "
if kafka-topics.sh --bootstrap-server localhost:9092 --list > /dev/null 2>&1; then
    echo "✓ Healthy"
else
    echo "✗ Unhealthy"
fi

# Redis Health
echo -n "Redis: "
if redis-cli -h localhost -p 6379 ping > /dev/null 2>&1; then
    echo "✓ Healthy"
else
    echo "✗ Unhealthy"
fi

# Dashboard Health
echo -n "Dashboard: "
if curl -sf http://localhost:8501/health > /dev/null; then
    echo "✓ Healthy"
else
    echo "✗ Unhealthy"
fi

echo "=== Health Check Complete ==="
```

## Appendix

### Useful Commands

```bash
# Development
make install-dev          # Install development dependencies
make docker-up            # Start all services
make health-check         # Check service health
make test                 # Run all tests
make lint                 # Run code linting

# Deployment
make docker-build         # Build Docker images
make k8s-deploy           # Deploy to Kubernetes
make helm-install         # Install with Helm
make production-deploy    # Production deployment

# Monitoring
make logs                 # View application logs
make metrics              # Display metrics
make traces               # View distributed traces

# Maintenance
make backup               # Create backup
make restore              # Restore from backup
make clean                # Clean up resources
```

### Configuration Templates

See the `config/` directory for complete configuration templates for each environment.

### Security Checklist

- [ ] All secrets stored in secure secret management system
- [ ] TLS/SSL enabled for all communications
- [ ] Network policies configured
- [ ] Container security contexts set
- [ ] Regular security scans performed
- [ ] Access controls properly configured
- [ ] Audit logging enabled
- [ ] Data encryption at rest and in transit

This deployment guide provides comprehensive instructions for deploying the E-Commerce Analytics Platform across different environments with proper configuration, security, monitoring, and maintenance procedures.
