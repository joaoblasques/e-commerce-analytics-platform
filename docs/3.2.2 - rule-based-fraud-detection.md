
# Rule-Based Fraud Detection Engine

This document describes the comprehensive rule-based fraud detection engine within the e-commerce analytics platform.

## Overview

The rule-based fraud detection engine is a sophisticated system that identifies suspicious transactions using configurable business rules, pattern analysis, merchant risk scoring, and intelligent alert prioritization. It supports both batch and real-time streaming processing for comprehensive fraud detection coverage.

## Architecture

The fraud detection system consists of five main components:

1. **Configurable Rules Engine**: Core business rules evaluation
2. **Transaction Pattern Analyzer**: Behavioral pattern detection
3. **Merchant Risk Scorer**: Merchant-based risk assessment
4. **Fraud Alert Prioritizer**: Intelligent alert management
5. **Fraud Detection Orchestrator**: Real-time coordination and streaming

## Key Features

### Rules Engine
- **Configurable Business Rules**: Define complex rules using SQL-like conditions
- **Multiple Rule Types**: Amount thresholds, velocity, patterns, merchant risk, location, time-based, and custom
- **Severity Levels**: LOW, MEDIUM, HIGH, CRITICAL with configurable weights
- **Dynamic Rule Management**: Add, remove, enable/disable rules at runtime
- **Rule Performance Tracking**: Monitor rule effectiveness and accuracy

### Pattern Analysis
- **Velocity Analysis**: Transaction frequency patterns across multiple time windows
- **Amount Pattern Detection**: Deviation from customer spending norms, z-score analysis
- **Time-Based Patterns**: Unusual hour detection, business hours analysis
- **Geographic Patterns**: Location-based anomaly detection
- **Payment Method Analysis**: Multiple payment method usage patterns
- **Merchant Interaction Patterns**: New merchant detection and relationship analysis

### Merchant Risk Scoring
- **Multi-Factor Risk Assessment**: Transaction volume, chargeback rates, customer diversity
- **Risk Level Classification**: VERY_LOW to VERY_HIGH risk levels
- **Behavioral Indicators**: Unusual transaction patterns, time-based anomalies
- **Dynamic Risk Flags**: Specific risk indicators for targeted investigation
- **Historical Performance Integration**: Past merchant behavior analysis

### Alert Prioritization
- **Intelligent Scoring**: Multi-factor priority calculation with configurable weights
- **Financial Impact Assessment**: Transaction amount-based risk evaluation
- **Time Sensitivity Analysis**: Recency-based priority adjustment
- **Investigation Guidance**: Recommended actions and time estimates
- **Priority Queue Management**: Organized workflow for fraud analysts

### Real-Time Processing
- **Streaming Integration**: Apache Spark Structured Streaming support
- **Configurable Processing**: Adjustable batch intervals and watermarks
- **Multiple Output Sinks**: Console, Delta Lake, Kafka integration
- **Batch Model Updates**: Periodic risk model updates and maintenance

## Usage Examples

### Basic Fraud Detection

```python
from src.analytics.fraud_detection import FraudDetectionOrchestrator
from pyspark.sql import SparkSession

# Initialize components
spark = SparkSession.builder.appName("FraudDetection").getOrCreate()
orchestrator = FraudDetectionOrchestrator(spark)

# Load transaction data
transactions_df = spark.read.format("delta").load("data/delta/transactions")

# Apply fraud detection pipeline
pattern_analyzer = orchestrator.pattern_analyzer
enriched_df = pattern_analyzer.create_comprehensive_patterns(transactions_df)
fraud_results = orchestrator.rules_engine.apply_rules(enriched_df)

# Get fraud alerts
fraud_alerts = fraud_results.filter(F.col("fraud_score") > 0)
fraud_alerts.show()
```

### Custom Rule Creation

```python
from src.analytics.fraud_detection import FraudRule, RuleType, RuleSeverity

# Create custom fraud rule
custom_rule = FraudRule(
    id="high_velocity_cards",
    name="High Velocity Credit Card Usage", 
    description="Flag customers using credit cards more than 10 times per hour",
    rule_type=RuleType.VELOCITY,
    severity=RuleSeverity.HIGH,
    condition="distinct_payment_methods_1h > 2 AND transaction_count_1h > 10"
)

# Add to rules engine
orchestrator.add_custom_rule(custom_rule)
```

### Real-Time Streaming Detection

```python
# Configure for real-time processing
config = {
    'stream_source_path': 'data/delta/transactions',
    'output_path': 'data/delta/fraud_alerts_stream',
    'batch_interval': '30 seconds',
    'watermark_delay': '5 minutes',
    'enable_pattern_analysis': True,
    'enable_merchant_scoring': True,
    'enable_alert_prioritization': True
}

orchestrator = FraudDetectionOrchestrator(spark, config)

# Start real-time detection
streaming_query = orchestrator.start_real_time_detection(output_sink="delta")
streaming_query.awaitTermination()
```

### Merchant Risk Analysis

```python
from src.analytics.fraud_detection import MerchantRiskScorer

# Initialize merchant risk scorer
risk_scorer = MerchantRiskScorer(spark)

# Calculate risk scores
merchant_scores = risk_scorer.calculate_merchant_risk_scores(transactions_df)

# Get high-risk merchants
high_risk_merchants = risk_scorer.get_high_risk_merchants(merchant_scores, min_risk_score=0.6)
high_risk_merchants.show()

# Detailed merchant analysis
merchant_analysis = risk_scorer.analyze_merchant_transaction_patterns(
    transactions_df, "merchant_001"
)
print(merchant_analysis)
```

### Alert Prioritization

```python
from src.analytics.fraud_detection import FraudAlertPrioritizer

# Initialize alert prioritizer
prioritizer = FraudAlertPrioritizer(spark)

# Prioritize fraud alerts
prioritized_alerts = prioritizer.prioritize_alerts(fraud_alerts)

# Get priority queue for investigation
priority_queue = prioritizer.get_priority_queue(prioritized_alerts, max_alerts=50)
priority_queue.select("transaction_id", "alert_priority", "priority_score", 
                     "recommended_actions", "estimated_investigation_time_minutes").show()

# Get summary metrics
metrics = prioritizer.get_alert_summary_metrics(prioritized_alerts)
print("Priority Breakdown:", metrics['priority_breakdown'])
```

## Configuration

### Rule Configuration File (JSON)

```json
{
  "rules": [
    {
      "id": "high_amount_threshold",
      "name": "High Amount Threshold",
      "description": "Flag transactions above $10,000",
      "rule_type": "amount_threshold",
      "severity": "high", 
      "condition": "price > 10000",
      "enabled": true,
      "weight": 1.0
    },
    {
      "id": "velocity_check_hourly",
      "name": "Hourly Velocity Check",
      "description": "Flag users with >5 transactions in 1 hour",
      "rule_type": "velocity",
      "severity": "medium",
      "condition": "transaction_count_1h > 5",
      "enabled": true,
      "weight": 1.2
    }
  ]
}
```

### Orchestrator Configuration

```python
config = {
    # Data paths
    'stream_source_path': 'data/delta/transactions',
    'output_path': 'data/delta/fraud_alerts',
    'checkpoint_location': 'data/checkpoints/fraud_detection',
    
    # Streaming settings
    'batch_interval': '30 seconds',
    'watermark_delay': '10 minutes',
    
    # Feature flags
    'enable_pattern_analysis': True,
    'enable_merchant_scoring': True,
    'enable_alert_prioritization': True,
    
    # Alert actions
    'alert_thresholds': {
        'critical_priority_action': 'immediate_block',
        'high_priority_action': 'manual_review',
        'medium_priority_action': 'queue_review',
        'low_priority_action': 'batch_review'
    },
    
    # Maintenance
    'model_update_interval': '1 hour'
}
```

## Advanced Features

### Performance Monitoring

```python
# Get system status
status = orchestrator.get_system_status()
print(f"Active Streams: {len(status['active_streams'])}")
print(f"Total Rules: {status['total_rules']}")
print(f"Enabled Rules: {status['enabled_rules']}")

# Get detection metrics
metrics = orchestrator.get_detection_metrics(time_window="1 hour")
print(f"Total Alerts: {metrics['total_alerts']}")
print(f"Financial Exposure: ${metrics['total_financial_exposure']:,.2f}")
```

### Rule Performance Analysis

```python
# Apply rules and get statistics
fraud_results = orchestrator.rules_engine.apply_rules(enriched_df)
rule_stats = orchestrator.rules_engine.get_rule_statistics(fraud_results)

for rule_id, stats in rule_stats.items():
    print(f"Rule: {stats['name']}")
    print(f"  Trigger Rate: {stats['trigger_rate']:.2%}")
    print(f"  Average Score: {stats.get('avg_score_when_triggered', 0):.3f}")
```

### Batch Model Updates

```python
# Update merchant risk scores and customer profiles
orchestrator.process_batch_updates()
```

## Output Schema

### Fraud Detection Results

```
transaction_id: string
customer_id: string  
merchant_id: string
price: double
fraud_score: double (0.0 to 1.0+)
fraud_risk_level: string (NONE, LOW, MEDIUM, HIGH, CRITICAL)
triggered_rules: array<string>
fraud_alerts: array<struct>
  - rule_id: string
  - rule_name: string
  - severity: string
  - score: double
  - message: string
```

### Prioritized Alerts

```
alert_id: string
transaction_id: string
customer_id: string
merchant_id: string
alert_priority: string (CRITICAL, HIGH, MEDIUM, LOW)
priority_score: double
financial_impact_factor: double
recommended_actions: array<string>
estimated_investigation_time_minutes: integer
processing_timestamp: timestamp
```

### Merchant Risk Scores

```
merchant_id: string
merchant_risk_score: double (0.0 to 1.0)
merchant_risk_level: string (VERY_LOW to VERY_HIGH)
transaction_count: integer
total_revenue: double
unique_customers: integer
risk_flags: array<string>
```

## Testing

Run the comprehensive test suite:

```bash
# Run all fraud detection tests
pytest tests/test_fraud_detection.py -v

# Run specific test categories
pytest tests/test_fraud_detection.py::TestConfigurableRulesEngine -v
pytest tests/test_fraud_detection.py::TestTransactionPatternAnalyzer -v
pytest tests/test_fraud_detection.py::TestMerchantRiskScorer -v
pytest tests/test_fraud_detection.py::TestFraudAlertPrioritizer -v
pytest tests/test_fraud_detection.py::TestIntegration -v
```

## Examples

See comprehensive usage examples in:
- `examples/fraud_detection_examples.py`

Run examples:
```bash
cd examples
python fraud_detection_examples.py
```

## Performance Considerations

- **Streaming Optimization**: Use appropriate batch intervals and watermarks
- **Memory Management**: Configure Spark memory settings for large datasets  
- **Checkpointing**: Regular checkpoint cleanup for long-running streams
- **Rule Complexity**: Balance rule sophistication with processing performance
- **Model Updates**: Schedule batch updates during low-traffic periods

## Integration

The fraud detection system integrates with:
- **Apache Spark**: Core processing engine
- **Delta Lake**: Data storage and streaming
- **Kafka**: Real-time message streaming (optional)
- **Existing Analytics**: Customer analytics and risk management systems

## Troubleshooting

### Common Issues

1. **Streaming Query Failures**: Check checkpoint locations and permissions
2. **Rule Parsing Errors**: Validate SQL syntax in rule conditions
3. **Memory Issues**: Increase Spark executor memory for large datasets
4. **Performance Degradation**: Review rule complexity and data partitioning

### Logging

Enable detailed logging:
```python
import logging
logging.getLogger("src.analytics.fraud_detection").setLevel(logging.DEBUG)
```
