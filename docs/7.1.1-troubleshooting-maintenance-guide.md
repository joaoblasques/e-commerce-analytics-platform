# E-Commerce Analytics Platform - Troubleshooting & Maintenance Guide

## Overview

This guide provides comprehensive troubleshooting procedures, maintenance tasks, and operational best practices for the E-Commerce Analytics Platform (ECAP). It includes common issues, diagnostic procedures, preventive maintenance, and emergency response protocols.

## Table of Contents

1. [Quick Diagnostics](#quick-diagnostics)
2. [Common Issues & Solutions](#common-issues--solutions)
3. [Performance Troubleshooting](#performance-troubleshooting)
4. [Data Pipeline Issues](#data-pipeline-issues)
5. [Infrastructure Problems](#infrastructure-problems)
6. [Security Issues](#security-issues)
7. [Preventive Maintenance](#preventive-maintenance)
8. [Emergency Procedures](#emergency-procedures)
9. [Monitoring & Alerting](#monitoring--alerting)
10. [Log Analysis](#log-analysis)
11. [Maintenance Schedules](#maintenance-schedules)
12. [Recovery Procedures](#recovery-procedures)

## Quick Diagnostics

### System Health Check

Run this comprehensive health check first for any issues:

```bash
#!/bin/bash
# quick-health-check.sh

echo "=== ECAP Quick Health Check ==="
echo "Timestamp: $(date -u)"
echo

# Service Status
echo "üîç Service Status:"
services=("api:8000" "dashboard:8501" "postgres:5432" "kafka:9092" "redis:6379")
for service in "${services[@]}"; do
    IFS=':' read -r host port <<< "$service"
    if nc -z "$host" "$port" 2>/dev/null; then
        echo "  ‚úÖ $service - UP"
    else
        echo "  ‚ùå $service - DOWN"
    fi
done

# API Health
echo
echo "üåê API Health:"
api_response=$(curl -s -o /dev/null -w "%{http_code}" http://localhost:8000/health)
if [ "$api_response" -eq 200 ]; then
    echo "  ‚úÖ API Health Check - OK"
else
    echo "  ‚ùå API Health Check - Failed ($api_response)"
fi

# Database Connection
echo
echo "üóÑÔ∏è Database Status:"
if pg_isready -h localhost -p 5432 >/dev/null 2>&1; then
    echo "  ‚úÖ Database - Accepting connections"

    # Check active connections
    active_conn=$(psql -h localhost -U ecap_user -d ecap -t -c "SELECT count(*) FROM pg_stat_activity;" 2>/dev/null | xargs)
    echo "  üìä Active connections: $active_conn"
else
    echo "  ‚ùå Database - Not accepting connections"
fi

# Kafka Topics
echo
echo "üì® Kafka Status:"
if kafka-topics.sh --bootstrap-server localhost:9092 --list >/dev/null 2>&1; then
    echo "  ‚úÖ Kafka - Accessible"

    # Check consumer lag
    lag=$(kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group ecap-consumer-group 2>/dev/null | awk 'NR>1 {sum+=$5} END {print sum}')
    if [ -n "$lag" ] && [ "$lag" -gt 0 ]; then
        echo "  ‚ö†Ô∏è Consumer lag: $lag messages"
    else
        echo "  ‚úÖ No consumer lag"
    fi
else
    echo "  ‚ùå Kafka - Not accessible"
fi

# Redis Status
echo
echo "üíæ Redis Status:"
if redis-cli -h localhost -p 6379 ping >/dev/null 2>&1; then
    echo "  ‚úÖ Redis - Accessible"

    # Check memory usage
    memory_used=$(redis-cli -h localhost -p 6379 info memory | grep used_memory_human | cut -d: -f2 | tr -d '\r')
    echo "  üìä Memory used: $memory_used"
else
    echo "  ‚ùå Redis - Not accessible"
fi

# Disk Space
echo
echo "üíø Disk Space:"
df -h | grep -E '(/$|/var|/tmp)' | while read output; do
    usage=$(echo "$output" | awk '{print $5}' | sed 's/%//g')
    partition=$(echo "$output" | awk '{print $6}')
    if [ "$usage" -gt 80 ]; then
        echo "  ‚ö†Ô∏è $partition: ${usage}% (Warning)"
    elif [ "$usage" -gt 90 ]; then
        echo "  ‚ùå $partition: ${usage}% (Critical)"
    else
        echo "  ‚úÖ $partition: ${usage}% (OK)"
    fi
done

# System Load
echo
echo "‚ö° System Performance:"
load=$(uptime | awk -F'load average:' '{print $2}' | awk '{print $1}' | sed 's/,//')
cpu_count=$(nproc)
load_percent=$(echo "$load * 100 / $cpu_count" | bc -l | cut -d. -f1)

if [ "$load_percent" -gt 80 ]; then
    echo "  ‚ö†Ô∏è System load: ${load_percent}% (High)"
else
    echo "  ‚úÖ System load: ${load_percent}% (Normal)"
fi

echo
echo "=== Health Check Complete ==="
```

### Quick Fix Commands

```bash
# Restart all services
make docker-restart

# Clear caches
redis-cli FLUSHALL
docker system prune -f

# Reset Kafka consumer groups
kafka-consumer-groups.sh --bootstrap-server localhost:9092 --group ecap-consumer-group --reset-offsets --to-latest --all-topics --execute

# Restart specific service
docker-compose restart api
kubectl rollout restart deployment/ecap-api

# Check recent logs
docker-compose logs --tail=50 api
kubectl logs deployment/ecap-api --tail=50
```

## Common Issues & Solutions

### 1. API Service Issues

#### Issue: API Returns 500 Internal Server Error

**Symptoms:**
- API endpoints returning HTTP 500 errors
- Error messages in API logs
- Dashboard unable to load data

**Diagnostic Steps:**
```bash
# Check API logs
docker-compose logs api --tail=100

# Test specific endpoint
curl -v http://localhost:8000/api/v1/health

# Check database connectivity from API
docker-compose exec api python -c "
from src.database.utils import test_connection
print('DB Connection:', test_connection())
"

# Verify environment variables
docker-compose exec api env | grep ECAP_
```

**Common Causes & Solutions:**

1. **Database Connection Issues:**
```bash
# Check database status
pg_isready -h localhost -p 5432

# Restart database
docker-compose restart postgres

# Check connection pool
psql -h localhost -U ecap_user -d ecap -c "SELECT count(*) FROM pg_stat_activity;"
```

2. **Configuration Issues:**
```bash
# Validate configuration
docker-compose exec api python -c "
from src.config.manager import get_settings
settings = get_settings()
print('Config loaded successfully')
print(f'Database URL: {settings.database_url}')
"

# Check missing environment variables
docker-compose exec api python -c "
import os
required_vars = ['ECAP_DATABASE_URL', 'ECAP_SECRET_KEY', 'ECAP_KAFKA_BOOTSTRAP_SERVERS']
for var in required_vars:
    print(f'{var}: {\"SET\" if os.getenv(var) else \"MISSING\"}')"
```

3. **Memory Issues:**
```bash
# Check container memory usage
docker stats api --no-stream

# Increase memory limit
# In docker-compose.yml:
# services:
#   api:
#     deploy:
#       resources:
#         limits:
#           memory: 2G
```

#### Issue: API Slow Response Times

**Symptoms:**
- API responses taking >5 seconds
- Timeout errors in client applications
- High CPU usage in API container

**Diagnostic Steps:**
```bash
# Profile API performance
curl -w "@curl-format.txt" -o /dev/null -s http://localhost:8000/api/v1/analytics/revenue

# Check database query performance
psql -h localhost -U ecap_user -d ecap -c "
SELECT query, calls, total_time, mean_time, rows
FROM pg_stat_statements
ORDER BY total_time DESC
LIMIT 10;
"

# Monitor API metrics
curl http://localhost:8000/metrics | grep http_request_duration
```

**Solutions:**

1. **Enable Query Optimization:**
```sql
-- Add missing indexes
CREATE INDEX CONCURRENTLY idx_transactions_customer_timestamp
ON transactions(customer_id, created_at);

CREATE INDEX CONCURRENTLY idx_customers_segment_active
ON customers(rfm_segment, is_active)
WHERE is_active = true;
```

2. **Implement Caching:**
```python
# Enable Redis caching
@cached(ttl=300)  # 5 minutes
def get_revenue_summary():
    return calculate_revenue_metrics()
```

3. **Scale API Service:**
```bash
# Scale horizontally
docker-compose up --scale api=3

# Or in Kubernetes
kubectl scale deployment ecap-api --replicas=3
```

### 2. Database Issues

#### Issue: Database Connection Pool Exhausted

**Symptoms:**
- "connection pool exhausted" errors
- New connections timing out
- API returning 503 Service Unavailable

**Diagnostic Steps:**
```bash
# Check active connections
psql -h localhost -U ecap_user -d ecap -c "
SELECT
    count(*) as total_connections,
    count(*) FILTER (WHERE state = 'active') as active,
    count(*) FILTER (WHERE state = 'idle') as idle
FROM pg_stat_activity;
"

# Check connection sources
psql -h localhost -U ecap_user -d ecap -c "
SELECT client_addr, count(*)
FROM pg_stat_activity
GROUP BY client_addr
ORDER BY count DESC;
"

# Check max connections setting
psql -h localhost -U ecap_user -d ecap -c "SHOW max_connections;"
```

**Solutions:**

1. **Increase Connection Pool Size:**
```yaml
# config/production.yaml
database:
  pool_size: 50
  max_overflow: 100
  pool_timeout: 30
```

2. **Implement Connection Pooling:**
```bash
# Install pgbouncer
docker run -d --name pgbouncer \
  -p 6432:6432 \
  -e DATABASES_HOST=postgres \
  -e DATABASES_PORT=5432 \
  -e DATABASES_USER=ecap_user \
  -e DATABASES_PASSWORD=password \
  -e DATABASES_DBNAME=ecap \
  pgbouncer/pgbouncer
```

3. **Monitor and Kill Long-Running Queries:**
```sql
-- Find long-running queries
SELECT
    pid,
    now() - pg_stat_activity.query_start AS duration,
    query
FROM pg_stat_activity
WHERE (now() - pg_stat_activity.query_start) > interval '5 minutes'
    AND state = 'active';

-- Kill problematic queries
SELECT pg_terminate_backend(pid) FROM pg_stat_activity
WHERE (now() - pg_stat_activity.query_start) > interval '10 minutes'
    AND state = 'active';
```

#### Issue: Database Disk Space Full

**Symptoms:**
- "No space left on device" errors
- Database write operations failing
- System becoming unresponsive

**Immediate Actions:**
```bash
# Check disk usage
df -h
du -sh /var/lib/postgresql/data/*

# Emergency cleanup
docker-compose exec postgres psql -U ecap_user -d ecap -c "VACUUM FULL;"

# Clean up old WAL files
docker-compose exec postgres find /var/lib/postgresql/data/pg_wal -name "*.gz" -mtime +7 -delete

# Archive old logs
docker-compose exec postgres find /var/lib/postgresql/data/log -name "*.log" -mtime +7 -exec gzip {} \;
```

**Long-term Solutions:**
```sql
-- Set up automatic cleanup
ALTER SYSTEM SET log_rotation_age = '1d';
ALTER SYSTEM SET log_rotation_size = '100MB';
ALTER SYSTEM SET log_filename = 'postgresql-%Y-%m-%d_%H%M%S.log';

-- Configure WAL retention
ALTER SYSTEM SET wal_keep_segments = 64;
ALTER SYSTEM SET archive_command = 'test ! -f /archive/%f && cp %p /archive/%f';

SELECT pg_reload_conf();
```

### 3. Kafka Issues

#### Issue: Kafka Consumer Lag

**Symptoms:**
- Delayed data processing
- Real-time dashboards showing stale data
- Consumer group lag increasing

**Diagnostic Steps:**
```bash
# Check consumer group status
kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group ecap-consumer-group

# Check topic details
kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic transactions

# Monitor producer throughput
kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic transactions --group test-group
```

**Solutions:**

1. **Scale Consumers:**
```bash
# Increase consumer instances
docker-compose up --scale streaming=3

# Or add more partitions to topics
kafka-topics.sh --bootstrap-server localhost:9092 --alter --topic transactions --partitions 12
```

2. **Optimize Consumer Configuration:**
```yaml
# config/production.yaml
kafka:
  consumer:
    max_poll_records: 2000
    fetch_min_bytes: 50000
    fetch_max_wait_ms: 500
    session_timeout_ms: 30000
```

3. **Reset Consumer Offset (if acceptable):**
```bash
# Reset to latest (skip old messages)
kafka-consumer-groups.sh --bootstrap-server localhost:9092 --group ecap-consumer-group --reset-offsets --to-latest --all-topics --execute

# Reset to specific timestamp
kafka-consumer-groups.sh --bootstrap-server localhost:9092 --group ecap-consumer-group --reset-offsets --to-datetime 2024-01-15T10:00:00.000 --all-topics --execute
```

#### Issue: Kafka Broker Down

**Symptoms:**
- Producer unable to send messages
- Consumer unable to fetch messages
- Kafka connection errors in logs

**Diagnostic Steps:**
```bash
# Check Kafka broker status
docker-compose ps kafka
kubectl get pods -l app=kafka

# Check Kafka logs
docker-compose logs kafka --tail=100
kubectl logs deployment/kafka --tail=100

# Test connectivity
kafka-broker-api-versions.sh --bootstrap-server localhost:9092
```

**Solutions:**

1. **Restart Kafka Broker:**
```bash
# Docker Compose
docker-compose restart kafka

# Kubernetes
kubectl rollout restart deployment/kafka
```

2. **Check Disk Space:**
```bash
# Kafka uses significant disk space for logs
df -h
docker-compose exec kafka df -h /var/lib/kafka/data

# Clean up old log segments
docker-compose exec kafka kafka-log-dirs.sh --bootstrap-server localhost:9092 --describe
```

3. **Verify Zookeeper Connection:**
```bash
# Check Zookeeper status
docker-compose exec zookeeper zkServer.sh status

# Check Kafka registration in Zookeeper
docker-compose exec zookeeper zkCli.sh -server localhost:2181 ls /brokers/ids
```

### 4. Redis Issues

#### Issue: Redis Memory Usage High

**Symptoms:**
- Redis using excessive memory
- Performance degradation
- Out of memory errors

**Diagnostic Steps:**
```bash
# Check Redis memory usage
redis-cli INFO memory

# Check key statistics
redis-cli INFO keyspace

# Find memory usage by key pattern
redis-cli --bigkeys

# Sample key types and sizes
redis-cli MEMORY USAGE some-key-name
```

**Solutions:**

1. **Configure Memory Policies:**
```bash
# Set memory limit and eviction policy
redis-cli CONFIG SET maxmemory 2gb
redis-cli CONFIG SET maxmemory-policy allkeys-lru

# Make changes persistent
redis-cli CONFIG REWRITE
```

2. **Cleanup Expired Keys:**
```bash
# Force cleanup of expired keys
redis-cli EVAL "return redis.pcall('DEL', unpack(redis.pcall('KEYS', ARGV[1])))" 0 "cache:*"

# Set appropriate TTL for cache keys
redis-cli EXPIRE "cache:revenue:2024-01-15" 3600
```

3. **Optimize Data Structures:**
```python
# Use appropriate Redis data types
# Instead of storing JSON as strings, use Redis hashes
redis_client.hset("user:123", mapping={
    "name": "John Doe",
    "email": "john@example.com",
    "segment": "premium"
})
```

## Performance Troubleshooting

### Slow Query Identification

#### Database Query Performance

```sql
-- Enable pg_stat_statements (in postgresql.conf)
shared_preload_libraries = 'pg_stat_statements'
pg_stat_statements.track = all

-- Find slowest queries
SELECT
    query,
    calls,
    total_time,
    total_time/calls as avg_time,
    rows,
    100.0 * shared_blks_hit / nullif(shared_blks_hit + shared_blks_read, 0) AS hit_percent
FROM pg_stat_statements
ORDER BY total_time DESC
LIMIT 20;

-- Find queries with high I/O
SELECT
    query,
    calls,
    shared_blks_read,
    shared_blks_written,
    temp_blks_read,
    temp_blks_written
FROM pg_stat_statements
WHERE shared_blks_read > 1000
ORDER BY shared_blks_read DESC
LIMIT 10;
```

#### Application Performance Profiling

```python
# Enable application profiling
import cProfile
import pstats
from functools import wraps

def profile_endpoint(func):
    @wraps(func)
    def wrapper(*args, **kwargs):
        pr = cProfile.Profile()
        pr.enable()
        result = func(*args, **kwargs)
        pr.disable()

        # Save profile data
        pr.dump_stats(f'/tmp/profile_{func.__name__}.prof')
        return result
    return wrapper

# Analyze profile data
stats = pstats.Stats('/tmp/profile_get_revenue.prof')
stats.sort_stats('cumulative').print_stats(20)
```

### Memory Analysis

#### JVM Memory Analysis (Spark)

```bash
# Generate heap dump
jmap -dump:format=b,file=heap.hprof <spark-pid>

# Analyze heap usage
jstat -gc <spark-pid> 5s

# Check for memory leaks
jcmd <spark-pid> GC.class_histogram | head -20
```

#### Python Memory Profiling

```python
# Install memory profiler
pip install memory-profiler psutil

# Profile memory usage
from memory_profiler import profile

@profile
def memory_intensive_function():
    # Your code here
    pass

# Monitor memory usage over time
python -m memory_profiler script.py
```

### Network Performance

#### Connection Analysis

```bash
# Check network connections
netstat -tupln | grep :8000
ss -tupln | grep :8000

# Monitor network traffic
tcpdump -i any port 8000

# Check connection limits
ulimit -n
sysctl net.core.somaxconn
```

#### Bandwidth Monitoring

```bash
# Monitor network bandwidth
iftop -i eth0
nload eth0

# Check network errors
cat /proc/net/dev
ethtool eth0
```

## Data Pipeline Issues

### Streaming Pipeline Failures

#### Spark Streaming Issues

**Common Symptoms:**
- Streaming job failing with exceptions
- Increasing batch processing time
- Data loss or duplication

**Diagnostic Commands:**
```bash
# Check Spark UI
curl http://localhost:4040/api/v1/applications
curl http://localhost:4040/api/v1/applications/[app-id]/streaming/batches

# Check Spark logs
docker-compose logs streaming-consumer --tail=200
kubectl logs deployment/spark-streaming --tail=200

# Monitor Spark metrics
curl http://localhost:4040/metrics/json
```

**Common Solutions:**

1. **Increase Batch Duration:**
```python
# Increase batch interval for high-throughput scenarios
streaming_context = StreamingContext(spark_context, batch_duration=10)  # 10 seconds
```

2. **Optimize Checkpointing:**
```python
# Enable checkpointing for fault tolerance
streaming_context.checkpoint("s3://ecap-checkpoints/streaming/")

# Clean up old checkpoints
def cleanup_checkpoints():
    # Remove checkpoints older than 7 days
    pass
```

3. **Handle Backpressure:**
```yaml
# Spark configuration
spark:
  streaming:
    backpressure:
      enabled: true
      initialRate: 1000
    receiver:
      maxRate: 2000
```

### Data Quality Issues

#### Schema Evolution Problems

```python
# Handle schema evolution gracefully
from pyspark.sql.types import StructType, StructField, StringType, IntegerType

def merge_schemas(schema1, schema2):
    """Merge two schemas, handling new fields gracefully."""
    fields_dict = {field.name: field for field in schema1.fields}

    for field in schema2.fields:
        if field.name not in fields_dict:
            fields_dict[field.name] = field

    return StructType(list(fields_dict.values()))

# Apply schema evolution
current_schema = df.schema
evolved_schema = merge_schemas(current_schema, new_data_schema)
df_evolved = df.select(*[col(field.name) for field in evolved_schema.fields])
```

#### Data Validation Failures

```python
# Implement data validation rules
from pyspark.sql.functions import col, when, isnan, isnull

def validate_transactions(df):
    """Validate transaction data quality."""

    # Check for null values in critical fields
    null_checks = df.select(
        col("transaction_id").isNull().alias("null_transaction_id"),
        col("customer_id").isNull().alias("null_customer_id"),
        col("amount").isNull().alias("null_amount")
    )

    # Check for invalid values
    invalid_amounts = df.filter(col("amount") <= 0).count()
    future_dates = df.filter(col("timestamp") > current_timestamp()).count()

    validation_report = {
        "total_records": df.count(),
        "invalid_amounts": invalid_amounts,
        "future_dates": future_dates,
        "null_transaction_ids": null_checks.filter(col("null_transaction_id")).count()
    }

    return validation_report
```

## Infrastructure Problems

### Container Issues

#### Docker Container Problems

```bash
# Check container status
docker ps -a
docker-compose ps

# Inspect container details
docker inspect ecap-api

# Check container resources
docker stats --no-stream

# View container logs with timestamps
docker logs ecap-api --timestamps --tail=100

# Execute commands in container
docker exec -it ecap-api /bin/bash

# Check container file system
docker exec ecap-api df -h
docker exec ecap-api find /app -name "*.log" -size +100M
```

#### Kubernetes Pod Issues

```bash
# Check pod status
kubectl get pods -o wide
kubectl describe pod ecap-api-xxx

# Check pod logs
kubectl logs pod/ecap-api-xxx --previous
kubectl logs deployment/ecap-api --tail=100 -f

# Execute commands in pod
kubectl exec -it pod/ecap-api-xxx -- /bin/bash

# Check pod resources
kubectl top pods
kubectl describe pod ecap-api-xxx | grep -A 5 "Limits:"

# Debug failed pods
kubectl get events --sort-by=.metadata.creationTimestamp
kubectl logs pod/ecap-api-xxx --previous
```

### Storage Issues

#### Persistent Volume Problems

```bash
# Check persistent volumes
kubectl get pv
kubectl get pvc

# Check volume usage
kubectl exec deployment/postgres -- df -h

# Backup before fixes
kubectl exec deployment/postgres -- pg_dump ecap > backup.sql

# Resize persistent volume
kubectl patch pvc postgres-pvc -p '{"spec":{"resources":{"requests":{"storage":"100Gi"}}}}'
```

#### Object Storage Issues

```bash
# Test S3/MinIO connectivity
aws s3 ls s3://ecap-data-lake/ --endpoint-url http://localhost:9000

# Check bucket permissions
aws s3api get-bucket-policy --bucket ecap-data-lake --endpoint-url http://localhost:9000

# Test upload/download
echo "test data" | aws s3 cp - s3://ecap-data-lake/test.txt --endpoint-url http://localhost:9000
aws s3 cp s3://ecap-data-lake/test.txt - --endpoint-url http://localhost:9000
```

### Network Issues

#### Service Discovery Problems

```bash
# Test DNS resolution
nslookup postgres
dig postgres

# Test service connectivity
telnet postgres 5432
nc -zv postgres 5432

# Check network policies (Kubernetes)
kubectl get networkpolicies
kubectl describe networkpolicy ecap-network-policy

# Test inter-service communication
kubectl exec deployment/ecap-api -- curl -v http://postgres:5432
```

#### Load Balancer Issues

```bash
# Check load balancer status
kubectl get ingress
kubectl describe ingress ecap-ingress

# Test load balancer endpoints
curl -v http://api.ecap.example.com/health
curl -H "Host: api.ecap.example.com" http://load-balancer-ip/health

# Check SSL certificates
openssl s_client -connect api.ecap.example.com:443 -servername api.ecap.example.com
```

## Security Issues

### Authentication Problems

#### JWT Token Issues

```python
# Debug JWT token problems
import jwt
from datetime import datetime

def debug_jwt_token(token, secret_key):
    try:
        # Decode without verification first
        header = jwt.get_unverified_header(token)
        payload = jwt.decode(token, options={"verify_signature": False})

        print(f"Header: {header}")
        print(f"Payload: {payload}")
        print(f"Expires: {datetime.fromtimestamp(payload.get('exp', 0))}")

        # Try to verify
        verified = jwt.decode(token, secret_key, algorithms=["HS256"])
        print("Token verification: SUCCESS")
        return verified

    except jwt.ExpiredSignatureError:
        print("Token verification: EXPIRED")
    except jwt.InvalidTokenError as e:
        print(f"Token verification: INVALID - {e}")
    except Exception as e:
        print(f"Token verification: ERROR - {e}")
```

#### API Key Problems

```bash
# Check API key validity
curl -H "X-API-Key: your-api-key" http://localhost:8000/api/v1/health

# List API keys (admin only)
curl -H "Authorization: Bearer admin-token" http://localhost:8000/api/v1/auth/api-keys

# Rotate compromised API key
curl -X POST -H "Authorization: Bearer admin-token" \
  http://localhost:8000/api/v1/auth/api-keys/rotate \
  -d '{"key_id": "compromised-key-id"}'
```

### SSL/TLS Issues

#### Certificate Problems

```bash
# Check certificate validity
openssl x509 -in /etc/ssl/certs/ecap.crt -text -noout
openssl x509 -in /etc/ssl/certs/ecap.crt -checkend 86400  # Check if expires in 24h

# Test SSL connection
openssl s_client -connect api.ecap.example.com:443 -servername api.ecap.example.com

# Verify certificate chain
openssl verify -CAfile /etc/ssl/certs/ca.crt /etc/ssl/certs/ecap.crt

# Check certificate expiration dates
echo | openssl s_client -connect api.ecap.example.com:443 2>/dev/null | openssl x509 -noout -dates
```

#### SSL Configuration Issues

```bash
# Test SSL configuration
nmap --script ssl-enum-ciphers api.ecap.example.com -p 443

# Check for weak ciphers
testssl.sh https://api.ecap.example.com

# Verify HSTS headers
curl -I https://api.ecap.example.com | grep -i strict
```

## Preventive Maintenance

### Daily Maintenance Tasks

#### Automated Daily Checks

```bash
#!/bin/bash
# daily-maintenance.sh

echo "=== Daily Maintenance - $(date) ==="

# 1. Health checks
echo "üîç Running health checks..."
./scripts/health-check.sh > /var/log/ecap/daily-health-$(date +%Y%m%d).log

# 2. Backup verification
echo "üíæ Verifying backups..."
./scripts/verify-backups.sh

# 3. Log rotation
echo "üìã Rotating logs..."
logrotate /etc/logrotate.d/ecap

# 4. Cleanup temporary files
echo "üßπ Cleaning temporary files..."
find /tmp -name "ecap-*" -mtime +1 -delete
docker system prune -f --volumes

# 5. Check disk space
echo "üíø Checking disk space..."
df -h | awk '$5 > 80 {print "WARNING: " $0}'

# 6. Monitor critical metrics
echo "üìä Checking critical metrics..."
./scripts/check-metrics.sh

# 7. Security scan
echo "üîí Running security checks..."
./scripts/security-scan.sh

echo "=== Daily Maintenance Complete ==="
```

### Weekly Maintenance Tasks

#### Database Maintenance

```sql
-- Weekly database maintenance
-- Run during low-traffic periods

-- Update table statistics
ANALYZE;

-- Reorganize indexes
REINDEX DATABASE ecap;

-- Clean up old data (adjust retention as needed)
DELETE FROM audit_logs WHERE created_at < NOW() - INTERVAL '90 days';
DELETE FROM session_tokens WHERE expires_at < NOW();

-- Check for bloated tables
SELECT
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size,
    pg_size_pretty(pg_relation_size(schemaname||'.'||tablename)) as table_size,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename) - pg_relation_size(schemaname||'.'||tablename)) as index_size
FROM pg_tables
WHERE schemaname = 'public'
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;

-- Vacuum full on high-churn tables (during maintenance window)
VACUUM FULL audit_logs;
VACUUM FULL session_tokens;
```

#### Kafka Maintenance

```bash
#!/bin/bash
# weekly-kafka-maintenance.sh

echo "=== Weekly Kafka Maintenance ==="

# 1. Check topic sizes
echo "üìä Topic sizes:"
kafka-log-dirs.sh --bootstrap-server localhost:9092 --describe --json | \
  jq '.brokers[].logDirs[].partitions[] | {topic: .topic, partition: .partition, size: .size}' | \
  sort -k3 -nr

# 2. Clean up old log segments
echo "üßπ Cleaning old log segments..."
kafka-topics.sh --bootstrap-server localhost:9092 --list | while read topic; do
    kafka-configs.sh --bootstrap-server localhost:9092 --entity-type topics --entity-name "$topic" \
      --alter --add-config retention.ms=604800000  # 7 days
done

# 3. Check consumer group lag
echo "‚è±Ô∏è Consumer group lag:"
kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --all-groups

# 4. Rebalance partitions if needed
# (Only run if you have multiple brokers)
kafka-reassign-partitions.sh --bootstrap-server localhost:9092 --generate \
  --topics-to-move-json-file topics.json --broker-list "1,2,3"

echo "=== Kafka Maintenance Complete ==="
```

### Monthly Maintenance Tasks

#### Security Updates

```bash
#!/bin/bash
# monthly-security-maintenance.sh

echo "=== Monthly Security Maintenance ==="

# 1. Update dependencies
echo "üì¶ Updating dependencies..."
poetry update
npm audit fix

# 2. Rotate secrets
echo "üîê Rotating secrets..."
./scripts/rotate-secrets.sh

# 3. Certificate renewal check
echo "üìú Checking certificates..."
find /etc/ssl/certs -name "*.crt" -exec openssl x509 -in {} -checkend 2592000 -noout \; \
  -exec echo "Certificate {} expires within 30 days" \;

# 4. Security scan
echo "üîç Running security scan..."
bandit -r src/
safety check

# 5. Penetration testing
echo "üéØ Running penetration tests..."
./scripts/security-tests.sh

# 6. Access review
echo "üë• Access review..."
./scripts/access-review.sh

echo "=== Security Maintenance Complete ==="
```

#### Performance Optimization

```bash
#!/bin/bash
# monthly-performance-optimization.sh

echo "=== Monthly Performance Optimization ==="

# 1. Database performance analysis
echo "üóÑÔ∏è Database analysis..."
psql -h localhost -U ecap_user -d ecap -f scripts/performance-analysis.sql

# 2. Index analysis
echo "üìá Index analysis..."
psql -h localhost -U ecap_user -d ecap -c "
SELECT
    schemaname,
    tablename,
    attname,
    n_distinct,
    correlation
FROM pg_stats
WHERE schemaname = 'public'
    AND n_distinct > 100
ORDER BY n_distinct DESC;
"

# 3. Cache hit ratio analysis
echo "üíæ Cache analysis..."
redis-cli INFO stats | grep cache_hit_rate

# 4. Query performance review
echo "‚ö° Query performance review..."
./scripts/slow-query-analysis.sh

# 5. Resource utilization review
echo "üìä Resource utilization..."
./scripts/resource-analysis.sh

echo "=== Performance Optimization Complete ==="
```

## Emergency Procedures

### Service Outage Response

#### Critical Service Down

**Priority 1: API Service Down**

```bash
# Immediate Response (0-5 minutes)
echo "üö® CRITICAL: API Service Down"

# 1. Check service status
docker-compose ps api
kubectl get pods -l app=ecap-api

# 2. Quick restart attempt
docker-compose restart api
# OR
kubectl rollout restart deployment/ecap-api

# 3. Check for immediate errors
docker-compose logs api --tail=50
kubectl logs deployment/ecap-api --tail=50

# 4. Verify health after restart
sleep 30
curl -f http://localhost:8000/health

# 5. If still down, escalate to full incident response
if ! curl -f http://localhost:8000/health; then
    echo "üö® ESCALATING: API still down after restart"
    ./scripts/incident-response.sh "api-down"
fi
```

**Priority 1: Database Down**

```bash
# Immediate Response (0-10 minutes)
echo "üö® CRITICAL: Database Down"

# 1. Check database status
pg_isready -h localhost -p 5432

# 2. Check container/pod status
docker-compose ps postgres
kubectl get pods -l app=postgres

# 3. Check logs for errors
docker-compose logs postgres --tail=100
kubectl logs deployment/postgres --tail=100

# 4. Attempt restart (if safe)
docker-compose restart postgres
# OR
kubectl rollout restart deployment/postgres

# 5. Verify connection
sleep 60  # Give more time for database startup
pg_isready -h localhost -p 5432

# 6. If down, initiate disaster recovery
if ! pg_isready -h localhost -p 5432; then
    echo "üö® INITIATING DISASTER RECOVERY"
    ./scripts/database-disaster-recovery.sh
fi
```

### Data Recovery Procedures

#### Point-in-Time Database Recovery

```bash
#!/bin/bash
# database-recovery.sh

echo "=== Database Point-in-Time Recovery ==="

# Variables
RECOVERY_TIME="${1:-$(date -d '1 hour ago' --iso-8601=seconds)}"
BACKUP_LOCATION="${2:-s3://ecap-backups/postgres/latest.sql.gz}"

echo "üïê Recovery time: $RECOVERY_TIME"
echo "üì¶ Backup location: $BACKUP_LOCATION"

# 1. Stop applications
echo "üõë Stopping applications..."
docker-compose stop api dashboard streaming

# 2. Create backup of current state
echo "üíæ Creating emergency backup..."
pg_dump -h localhost -U ecap_user ecap | gzip > "emergency_backup_$(date +%Y%m%d_%H%M%S).sql.gz"

# 3. Download backup
echo "‚¨áÔ∏è Downloading backup..."
aws s3 cp "$BACKUP_LOCATION" /tmp/recovery.sql.gz

# 4. Drop and recreate database
echo "üóÑÔ∏è Recreating database..."
psql -h localhost -U postgres -c "DROP DATABASE IF EXISTS ecap;"
psql -h localhost -U postgres -c "CREATE DATABASE ecap OWNER ecap_user;"

# 5. Restore backup
echo "‚ôªÔ∏è Restoring backup..."
gunzip -c /tmp/recovery.sql.gz | psql -h localhost -U ecap_user -d ecap

# 6. Run migrations if needed
echo "üîÑ Running migrations..."
alembic upgrade head

# 7. Restart applications
echo "üöÄ Restarting applications..."
docker-compose up -d api dashboard streaming

# 8. Verify recovery
echo "‚úÖ Verifying recovery..."
sleep 30
curl -f http://localhost:8000/health

echo "=== Recovery Complete ==="
```

#### Kafka Data Recovery

```bash
#!/bin/bash
# kafka-recovery.sh

echo "=== Kafka Data Recovery ==="

RECOVERY_TIMESTAMP="${1:-$(date -d '1 hour ago' +%s)000}"  # Milliseconds

# 1. Stop consumers
echo "üõë Stopping consumers..."
docker-compose stop streaming

# 2. Reset consumer group to recovery point
echo "‚è™ Resetting consumer offsets..."
kafka-consumer-groups.sh --bootstrap-server localhost:9092 \
  --group ecap-consumer-group \
  --reset-offsets \
  --to-datetime "$RECOVERY_TIMESTAMP" \
  --all-topics \
  --execute

# 3. Restart consumers
echo "üöÄ Restarting consumers..."
docker-compose up -d streaming

# 4. Monitor replay progress
echo "üìä Monitoring replay progress..."
watch -n 5 "kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group ecap-consumer-group"

echo "=== Kafka Recovery Complete ==="
```

### Incident Response Playbook

#### Incident Classification

| Severity | Description | Response Time | Examples |
|----------|-------------|---------------|----------|
| P1 - Critical | Complete service outage | 5 minutes | API down, Database inaccessible |
| P2 - High | Major feature broken | 30 minutes | Fraud detection not working |
| P3 - Medium | Minor feature issues | 2 hours | Dashboard chart not loading |
| P4 - Low | Cosmetic issues | Next business day | UI formatting issues |

#### Incident Response Process

```bash
#!/bin/bash
# incident-response.sh

INCIDENT_TYPE="$1"
SEVERITY="${2:-P2}"
INCIDENT_ID="INC-$(date +%Y%m%d-%H%M%S)"

echo "üö® INCIDENT RESPONSE ACTIVATED"
echo "ID: $INCIDENT_ID"
echo "Type: $INCIDENT_TYPE"
echo "Severity: $SEVERITY"
echo "Time: $(date)"

# 1. Log incident
echo "$INCIDENT_ID,$INCIDENT_TYPE,$SEVERITY,$(date)" >> /var/log/ecap/incidents.log

# 2. Notify team (adjust notification method as needed)
if [ "$SEVERITY" = "P1" ]; then
    # Critical - notify immediately
    echo "üö® CRITICAL INCIDENT: $INCIDENT_ID - $INCIDENT_TYPE" | \
      mail -s "ECAP Critical Incident" oncall@example.com
elif [ "$SEVERITY" = "P2" ]; then
    # High - notify during business hours
    echo "‚ö†Ô∏è HIGH INCIDENT: $INCIDENT_ID - $INCIDENT_TYPE" | \
      mail -s "ECAP High Priority Incident" support@example.com
fi

# 3. Start incident tracking
mkdir -p "/var/log/ecap/incidents/$INCIDENT_ID"
echo "Incident: $INCIDENT_ID" > "/var/log/ecap/incidents/$INCIDENT_ID/timeline.log"
echo "Started: $(date)" >> "/var/log/ecap/incidents/$INCIDENT_ID/timeline.log"

# 4. Collect diagnostic information
echo "üìä Collecting diagnostics..."
./scripts/health-check.sh > "/var/log/ecap/incidents/$INCIDENT_ID/health-check.log"
docker-compose logs --tail=200 > "/var/log/ecap/incidents/$INCIDENT_ID/docker-logs.log"

# 5. Execute incident-specific response
case "$INCIDENT_TYPE" in
    "api-down")
        ./scripts/api-recovery.sh
        ;;
    "database-down")
        ./scripts/database-recovery.sh
        ;;
    "kafka-down")
        ./scripts/kafka-recovery.sh
        ;;
    "performance-degradation")
        ./scripts/performance-investigation.sh
        ;;
    *)
        echo "‚ö†Ô∏è Unknown incident type: $INCIDENT_TYPE"
        ;;
esac

echo "=== Incident Response Complete ==="
```

## Monitoring & Alerting

### Critical Alerts Configuration

#### Prometheus Alert Rules

```yaml
# alerts.yml - Critical alerts
groups:
- name: ecap.critical
  rules:
  - alert: APIServiceDown
    expr: up{job="ecap-api"} == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "ECAP API service is down"
      description: "API service has been down for more than 1 minute"
      runbook: "https://docs.internal/runbooks/api-down"

  - alert: DatabaseConnectionFailure
    expr: ecap_database_connections_failed_total > 0
    for: 30s
    labels:
      severity: critical
    annotations:
      summary: "Database connection failures detected"
      description: "{{ $value }} database connection failures"

  - alert: HighErrorRate
    expr: rate(ecap_api_requests_total{status=~"5.."}[5m]) > 0.1
    for: 2m
    labels:
      severity: critical
    annotations:
      summary: "High error rate detected"
      description: "Error rate is {{ $value }} errors per second"

  - alert: KafkaConsumerLag
    expr: kafka_consumer_lag_sum{group="ecap-consumer-group"} > 10000
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High Kafka consumer lag"
      description: "Consumer lag is {{ $value }} messages"

  - alert: DiskSpaceHigh
    expr: (1 - (node_filesystem_avail_bytes / node_filesystem_size_bytes)) * 100 > 85
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Disk space usage high"
      description: "Disk usage is {{ $value }}%"
```

### Custom Metrics Collection

```python
# Custom application metrics
from prometheus_client import Counter, Histogram, Gauge, start_http_server

# API metrics
request_count = Counter('ecap_api_requests_total', 'Total API requests', ['method', 'endpoint', 'status'])
request_duration = Histogram('ecap_api_request_duration_seconds', 'API request duration')
active_users = Gauge('ecap_active_users', 'Number of active users')

# Business metrics
transactions_processed = Counter('ecap_transactions_processed_total', 'Total transactions processed')
fraud_alerts_generated = Counter('ecap_fraud_alerts_total', 'Total fraud alerts', ['severity'])
customer_segments = Gauge('ecap_customer_segments_count', 'Customer count by segment', ['segment'])

# System metrics
database_connections = Gauge('ecap_database_connections_active', 'Active database connections')
kafka_consumer_lag = Gauge('ecap_kafka_consumer_lag', 'Kafka consumer lag', ['topic', 'partition'])
cache_hit_rate = Gauge('ecap_cache_hit_rate', 'Cache hit rate')

# Start metrics server
start_http_server(8080)
```

## Log Analysis

### Centralized Logging Setup

#### ELK Stack Configuration

```yaml
# docker-compose.elk.yml
version: '3.8'
services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.8.0
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data

  logstash:
    image: docker.elastic.co/logstash/logstash:8.8.0
    ports:
      - "5044:5044"
    volumes:
      - ./logging/logstash/pipeline:/usr/share/logstash/pipeline
      - ./logging/logstash/config:/usr/share/logstash/config

  kibana:
    image: docker.elastic.co/kibana/kibana:8.8.0
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200

volumes:
  elasticsearch-data:
```

#### Log Analysis Queries

```bash
# Common log analysis commands

# Find error patterns
grep -E "(ERROR|CRITICAL|FATAL)" /var/log/ecap/*.log | head -20

# Find slow queries
grep "slow query" /var/log/postgresql/*.log | tail -10

# API error analysis
jq '.level == "ERROR"' /var/log/ecap/api.log | head -10

# Performance analysis
awk '/request_duration/ {sum+=$NF; count++} END {print "Average:", sum/count}' /var/log/ecap/api.log

# Security analysis
grep -i "authentication" /var/log/ecap/api.log | grep -i "failed"
```

### Log Monitoring Scripts

```bash
#!/bin/bash
# log-monitor.sh

echo "=== Log Analysis Report ==="

# Error rate analysis
echo "üìä Error Rate (last hour):"
find /var/log/ecap -name "*.log" -newermt "1 hour ago" -exec \
  grep -h "ERROR\|CRITICAL\|FATAL" {} \; | wc -l

# Top error messages
echo "üîù Top Error Messages:"
find /var/log/ecap -name "*.log" -newermt "1 hour ago" -exec \
  grep -h "ERROR" {} \; | cut -d' ' -f4- | sort | uniq -c | sort -nr | head -5

# Performance issues
echo "‚ö° Performance Issues:"
find /var/log/ecap -name "*.log" -newermt "1 hour ago" -exec \
  grep -h "slow\|timeout\|latency" {} \; | wc -l

# Security events
echo "üîí Security Events:"
find /var/log/ecap -name "*.log" -newermt "1 hour ago" -exec \
  grep -hi "authentication\|authorization\|security" {} \; | wc -l

echo "=== Analysis Complete ==="
```

This comprehensive troubleshooting and maintenance guide provides the necessary procedures and scripts to effectively operate and maintain the E-Commerce Analytics Platform, ensuring high availability, performance, and security.
